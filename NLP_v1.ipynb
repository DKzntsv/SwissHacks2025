{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xgppxAUOzr",
        "outputId": "3654782f-602a-422b-87f2-dd7fbf32a3d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy nltk\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyWrucvCUbwO",
        "outputId": "112750a2-79d9-45dd-f200-2618a4da73fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import spacy\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "from nltk import pos_tag, word_tokenize\n",
        "import os"
      ],
      "metadata": {
        "id": "PNQPThXhUggQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtRO0EGWVEch",
        "outputId": "a4b3fb7b-b27a-4808-8891-e244ed618d66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClientDescriptionParser:\n",
        "    \"\"\"\n",
        "    A class to parse client description text files into structured JSON format\n",
        "    using natural language processing techniques with enhanced extraction capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the parser with NLP models.\"\"\"\n",
        "        # Load spaCy model\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        # Define common section headers that might appear in client descriptions\n",
        "        self.section_patterns = {\n",
        "            \"summary\": [r\"summary note\", r\"summary\", r\"client overview\", r\"overview\", r\"general information\", r\"client information\"],\n",
        "            \"family\": [r\"family background\", r\"family information\", r\"family\", r\"personal relationships\", r\"household\"],\n",
        "            \"education\": [r\"education background\", r\"education\", r\"academic background\", r\"academic history\", r\"qualifications\", r\"studies\"],\n",
        "            \"occupation\": [r\"occupation history\", r\"employment history\", r\"career\", r\"professional background\", r\"work history\", r\"job\"],\n",
        "            \"wealth\": [r\"wealth summary\", r\"financial summary\", r\"assets\", r\"financial status\", r\"finances\", r\"economic situation\", r\"net worth\"],\n",
        "            \"client_preferences\": [r\"preferences\", r\"interests\", r\"hobbies\", r\"likes\", r\"client interests\", r\"lifestyle\"],\n",
        "            \"risk_profile\": [r\"risk profile\", r\"risk tolerance\", r\"investment profile\", r\"risk assessment\", r\"risk attitude\"],\n",
        "            \"relationship_manager\": [r\"relationship manager\", r\"rm\", r\"advisor\", r\"client advisor\", r\"bank contact\"],\n",
        "            \"client_summary\": [r\"client summary\", r\"conclusion\", r\"final notes\", r\"assessment\", r\"evaluation\", r\"summary\"]\n",
        "        }\n",
        "\n",
        "    def _extract_sections(self, text):\n",
        "        \"\"\"\n",
        "        Extract sections from the text based on common headers.\n",
        "        Returns a dictionary with section names and their content.\n",
        "        \"\"\"\n",
        "        sections = {}\n",
        "        lines = text.strip().split('\\n')\n",
        "\n",
        "        # Preprocess to identify potential headers\n",
        "        potential_headers = []\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Look for typical header patterns\n",
        "            if re.match(r'^[A-Za-z\\s]+:$', line) or \\\n",
        "               (re.match(r'^[A-Za-z\\s]+$', line) and (i == 0 or not lines[i-1].strip()) and \\\n",
        "               (i == len(lines)-1 or not lines[i+1].strip() or len(line) < 30)):\n",
        "                potential_headers.append((i, line))\n",
        "\n",
        "        # Process text based on identified headers\n",
        "        if potential_headers:\n",
        "            section_boundaries = []\n",
        "\n",
        "            for i, (line_idx, header) in enumerate(potential_headers):\n",
        "                # Determine section type\n",
        "                section_match = False\n",
        "                current_section = \"unknown\"\n",
        "\n",
        "                for section_name, patterns in self.section_patterns.items():\n",
        "                    for pattern in patterns:\n",
        "                        if re.search(pattern, header.lower()):\n",
        "                            current_section = section_name\n",
        "                            section_match = True\n",
        "                            break\n",
        "                    if section_match:\n",
        "                        break\n",
        "\n",
        "                # If no match with known patterns, use the header as section name\n",
        "                if not section_match:\n",
        "                    current_section = header.lower().replace(':', '').strip()\n",
        "\n",
        "                # Record section boundary\n",
        "                if i < len(potential_headers) - 1:\n",
        "                    next_header_idx = potential_headers[i+1][0]\n",
        "                    section_boundaries.append((current_section, line_idx+1, next_header_idx))\n",
        "                else:\n",
        "                    section_boundaries.append((current_section, line_idx+1, len(lines)))\n",
        "\n",
        "            # Extract content for each section\n",
        "            for section_name, start, end in section_boundaries:\n",
        "                section_content = '\\n'.join(lines[start:end]).strip()\n",
        "                sections[section_name] = section_content\n",
        "        else:\n",
        "            # Handle case with no headers - try to identify sections based on content\n",
        "            current_section = \"unknown\"\n",
        "            current_content = []\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Check if this line might indicate a section based on content\n",
        "                section_match = False\n",
        "                for section_name, patterns in self.section_patterns.items():\n",
        "                    for pattern in patterns:\n",
        "                        if re.search(pattern, line.lower()):\n",
        "                            # If we've been building content for a previous section, save it\n",
        "                            if current_content:\n",
        "                                sections[current_section] = '\\n'.join(current_content)\n",
        "                                current_content = []\n",
        "                            current_section = section_name\n",
        "                            section_match = True\n",
        "                            break\n",
        "                    if section_match:\n",
        "                        break\n",
        "\n",
        "                # If it's not a section header, add to current content\n",
        "                if not section_match:\n",
        "                    current_content.append(line)\n",
        "\n",
        "            # Add the last section\n",
        "            if current_content:\n",
        "                sections[current_section] = '\\n'.join(current_content)\n",
        "\n",
        "        # If still no sections identified, treat entire text as unknown section\n",
        "        if not sections:\n",
        "            sections[\"unknown\"] = text\n",
        "\n",
        "        return sections\n",
        "\n",
        "    def _extract_personal_info(self, text):\n",
        "        \"\"\"Extract comprehensive personal information using NLP.\"\"\"\n",
        "        personal_info = {}\n",
        "        doc = self.nlp(text)\n",
        "\n",
        "        # Extract name and age using multiple patterns\n",
        "        name_age_patterns = [\n",
        "            r'([A-Za-z\\s]+) is (\\d+) years? old',\n",
        "            r'([A-Za-z\\s]+), (?:aged|age) (\\d+)',\n",
        "            r'(?:name is|client is) ([A-Za-z\\s]+), (\\d+)',\n",
        "            r'([A-Za-z\\s]+) \\((\\d+)\\)'\n",
        "        ]\n",
        "\n",
        "        for pattern in name_age_patterns:\n",
        "            name_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if name_match:\n",
        "                personal_info[\"name\"] = name_match.group(1).strip()\n",
        "                personal_info[\"age\"] = int(name_match.group(2))\n",
        "                break\n",
        "\n",
        "        # If name wasn't found, try to extract using NER\n",
        "        if \"name\" not in personal_info:\n",
        "            for entity in doc.ents:\n",
        "                if entity.label_ == \"PERSON\" and len(entity.text.split()) >= 2:\n",
        "                    personal_info[\"name\"] = entity.text\n",
        "                    break\n",
        "\n",
        "        # Extract nationality/country\n",
        "        nationality_patterns = [\n",
        "            r'from ([A-Za-z]+)',\n",
        "            r'nationality (?:is|:) ([A-Za-z]+)',\n",
        "            r'citizen of ([A-Za-z]+)',\n",
        "            r'(?:born|raised) in ([A-Za-z]+)',\n",
        "            r'([A-Za-z]+) national',\n",
        "            r'(?:is|a) ([A-Za-z]+) citizen'\n",
        "        ]\n",
        "\n",
        "        for pattern in nationality_patterns:\n",
        "            nationality_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if nationality_match:\n",
        "                personal_info[\"nationality\"] = nationality_match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # If nationality wasn't found, try NER\n",
        "        if \"nationality\" not in personal_info:\n",
        "            for entity in doc.ents:\n",
        "                if entity.label_ == \"GPE\" and len(entity.text) > 3:  # GPE = Geo-Political Entity\n",
        "                    # Use the first country mentioned\n",
        "                    personal_info[\"nationality\"] = entity.text\n",
        "                    break\n",
        "\n",
        "        # Extract date of birth\n",
        "        dob_patterns = [\n",
        "            r'born on (\\d{1,2})[\\/\\.\\-](\\d{1,2})[\\/\\.\\-](\\d{4})',\n",
        "            r'date of birth:? (\\d{1,2})[\\/\\.\\-](\\d{1,2})[\\/\\.\\-](\\d{4})',\n",
        "            r'DOB:? (\\d{1,2})[\\/\\.\\-](\\d{1,2})[\\/\\.\\-](\\d{4})',\n",
        "            r'born in (\\d{4})'\n",
        "        ]\n",
        "\n",
        "        for pattern in dob_patterns:\n",
        "            dob_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if dob_match:\n",
        "                if len(dob_match.groups()) == 3:\n",
        "                    personal_info[\"date_of_birth\"] = f\"{dob_match.group(1)}/{dob_match.group(2)}/{dob_match.group(3)}\"\n",
        "                else:\n",
        "                    personal_info[\"year_of_birth\"] = dob_match.group(1)\n",
        "                break\n",
        "\n",
        "        # Extract contact information\n",
        "        contact_patterns = {\n",
        "            \"email\": r'(?:email|e-mail):? ([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})',\n",
        "            \"phone\": r'(?:phone|telephone|mobile|contact number):? (\\+?[0-9\\s\\-().]{7,})',\n",
        "            \"address\": r'(?:address|residence|lives in|living at):? ([^\\.]+)'\n",
        "        }\n",
        "\n",
        "        for info_type, pattern in contact_patterns.items():\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                personal_info[info_type] = match.group(1).strip()\n",
        "\n",
        "        # Extract languages spoken\n",
        "        language_patterns = [\n",
        "            r'speaks? (?:fluent )?([A-Za-z,\\s]+) (?:and|&) ([A-Za-z]+)',\n",
        "            r'language(?:s)? spoken:? ([^\\.]+)',\n",
        "            r'fluent in ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in language_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                if len(match.groups()) == 2:\n",
        "                    languages = f\"{match.group(1)}, {match.group(2)}\"\n",
        "                else:\n",
        "                    languages = match.group(1)\n",
        "                personal_info[\"languages\"] = [lang.strip() for lang in re.split(r',|and|&', languages)]\n",
        "                break\n",
        "\n",
        "        # Extract gender using NLP\n",
        "        female_indicators = ['she', 'her', 'herself', 'woman', 'female', 'lady', 'Ms', 'Mrs', 'Miss']\n",
        "        male_indicators = ['he', 'him', 'himself', 'man', 'male', 'gentleman', 'Mr']\n",
        "\n",
        "        female_count = 0\n",
        "        male_count = 0\n",
        "\n",
        "        for token in doc:\n",
        "            if token.text.lower() in [s.lower() for s in female_indicators]:\n",
        "                female_count += 1\n",
        "            elif token.text.lower() in [s.lower() for s in male_indicators]:\n",
        "                male_count += 1\n",
        "\n",
        "        # Also check for gender specific titles\n",
        "        for female_title in ['Ms', 'Mrs', 'Miss']:\n",
        "            if re.search(r'\\b' + female_title + r'\\b', text):\n",
        "                female_count += 3  # Give more weight to titles\n",
        "\n",
        "        if re.search(r'\\bMr\\b', text):\n",
        "            male_count += 3  # Give more weight to titles\n",
        "\n",
        "        if female_count > male_count:\n",
        "            personal_info[\"gender\"] = \"Female\"\n",
        "        elif male_count > female_count:\n",
        "            personal_info[\"gender\"] = \"Male\"\n",
        "\n",
        "        # Extract profession using various patterns\n",
        "        profession_patterns = [\n",
        "            r'is an? ([A-Za-z\\s]+) (?:from|at|with)',\n",
        "            r'works as an? ([A-Za-z\\s]+)',\n",
        "            r'is employed as an? ([A-Za-z\\s]+)',\n",
        "            r'profession (?:is|:) ([A-Za-z\\s]+)',\n",
        "            r'(?:career|job|occupation) as an? ([A-Za-z\\s]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in profession_patterns:\n",
        "            profession_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if profession_match:\n",
        "                # Clean up common issues with profession extraction\n",
        "                profession = profession_match.group(1).strip()\n",
        "                # Remove articles and common issues\n",
        "                profession = re.sub(r'\\b(a|an|the)\\b', '', profession).strip()\n",
        "                personal_info[\"profession\"] = profession\n",
        "                break\n",
        "\n",
        "        # Extract relationship manager info using a separate function\n",
        "        rm_info = self._extract_rm_info(text)\n",
        "        if rm_info:\n",
        "            personal_info[\"relationship_manager\"] = rm_info\n",
        "\n",
        "        # Extract client ID or account number if present\n",
        "        id_patterns = [\n",
        "            r'client (?:ID|id|number):? ([A-Za-z0-9-]+)',\n",
        "            r'account (?:number|#):? ([A-Za-z0-9-]+)',\n",
        "            r'reference (?:number|#):? ([A-Za-z0-9-]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in id_patterns:\n",
        "            id_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if id_match:\n",
        "                personal_info[\"client_id\"] = id_match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        return personal_info\n",
        "\n",
        "    def _extract_rm_info(self, text):\n",
        "        \"\"\"Extract detailed relationship manager information.\"\"\"\n",
        "        rm_info = {}\n",
        "\n",
        "        # Extract relationship manager name and relation\n",
        "        rm_patterns = [\n",
        "            r'The RM is ([^\\']+)\\'s ([^,\\.]+)',\n",
        "            r'relationship manager is ([^\\']+)\\'s ([^,\\.]+)',\n",
        "            r'(?:assigned|appointed) (?:to|with) ([^\\']+) as (?:the|their) ([^,\\.]+)',\n",
        "            r'(?:managed|handled) by ([^,\\.]+)',\n",
        "            r'RM (?:is|:) ([^,\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in rm_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                if len(match.groups()) == 2:\n",
        "                    rm_info[\"name\"] = match.group(1).strip()\n",
        "                    rm_info[\"relation\"] = match.group(2).strip()\n",
        "                else:\n",
        "                    rm_info[\"name\"] = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # Extract relation details\n",
        "        relation_patterns = [\n",
        "            r'having married ([^\\.]+)',\n",
        "            r'being ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in relation_patterns:\n",
        "            relation_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if relation_match:\n",
        "                rm_info[\"details\"] = relation_match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # Extract relationship duration\n",
        "        duration_pattern = r'(?:relationship|client) for (\\d+) years'\n",
        "        match = re.search(duration_pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            rm_info[\"relationship_duration\"] = int(match.group(1))\n",
        "\n",
        "        # Extract office/branch information\n",
        "        office_pattern = r'(?:based in|office in|branch in|from) ([^,\\.]+) (?:office|branch)'\n",
        "        match = re.search(office_pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            rm_info[\"office_location\"] = match.group(1).strip()\n",
        "\n",
        "        return rm_info\n",
        "\n",
        "    def _extract_family_info(self, text):\n",
        "        \"\"\"Extract detailed family information.\"\"\"\n",
        "        family_info = {}\n",
        "\n",
        "        # Extract marital status using multiple patterns\n",
        "        marital_patterns = [\n",
        "            r'married to ([A-Za-z\\s]+)',\n",
        "            r'(?:husband|wife|spouse) is ([A-Za-z\\s]+)',\n",
        "            r'is ([A-Za-z\\s]+)\\'s (?:husband|wife|spouse)'\n",
        "        ]\n",
        "\n",
        "        for pattern in marital_patterns:\n",
        "            marital_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if marital_match:\n",
        "                family_info[\"marital_status\"] = \"Married\"\n",
        "                family_info[\"spouse_name\"] = marital_match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # Single status patterns\n",
        "        if \"marital_status\" not in family_info:\n",
        "            single_patterns = [r'is single', r'not married', r'unmarried']\n",
        "            for pattern in single_patterns:\n",
        "                if re.search(pattern, text, re.IGNORECASE):\n",
        "                    family_info[\"marital_status\"] = \"Single\"\n",
        "                    break\n",
        "\n",
        "            # Divorced status patterns\n",
        "            divorced_patterns = [r'is divorced', r'divorced from']\n",
        "            for pattern in divorced_patterns:\n",
        "                if re.search(pattern, text, re.IGNORECASE):\n",
        "                    family_info[\"marital_status\"] = \"Divorced\"\n",
        "                    break\n",
        "\n",
        "            # Widowed status patterns\n",
        "            widowed_patterns = [r'is widowed', r'widow', r'widower']\n",
        "            for pattern in widowed_patterns:\n",
        "                if re.search(pattern, text, re.IGNORECASE):\n",
        "                    family_info[\"marital_status\"] = \"Widowed\"\n",
        "                    break\n",
        "\n",
        "        # Extract children information with more patterns\n",
        "        children_patterns = [\n",
        "            r'(?:do not have any children|no children|does not have children|does not have any children)',\n",
        "            r'has (\\d+) (?:child|children|son|daughter|sons|daughters)',\n",
        "            r'have (\\d+) (?:child|children|son|daughter|sons|daughters)'\n",
        "        ]\n",
        "\n",
        "        for pattern in children_patterns:\n",
        "            children_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if children_match:\n",
        "                if \"do not\" in children_match.group(0).lower() or \"no children\" in children_match.group(0).lower() or \"does not\" in children_match.group(0).lower():\n",
        "                    family_info[\"has_children\"] = False\n",
        "                else:\n",
        "                    family_info[\"has_children\"] = True\n",
        "                    family_info[\"number_of_children\"] = int(children_match.group(1))\n",
        "                break\n",
        "\n",
        "        # Extract children's names and ages if available\n",
        "        if family_info.get(\"has_children\", False):\n",
        "            children_details_pattern = r'(?:children are|children named|named) ([^\\.]+)'\n",
        "            children_details_match = re.search(children_details_pattern, text, re.IGNORECASE)\n",
        "            if children_details_match:\n",
        "                children_details = children_details_match.group(1).strip()\n",
        "                children_list = []\n",
        "\n",
        "                # Try to parse children with ages\n",
        "                child_with_age_pattern = r'([A-Za-z]+) \\((\\d+)\\)'\n",
        "                child_with_age_matches = re.findall(child_with_age_pattern, children_details)\n",
        "\n",
        "                if child_with_age_matches:\n",
        "                    for name, age in child_with_age_matches:\n",
        "                        children_list.append({\"name\": name.strip(), \"age\": int(age)})\n",
        "                else:\n",
        "                    # Just get names\n",
        "                    children_names = [name.strip() for name in re.split(r',|and|&', children_details)]\n",
        "                    children_list = [{\"name\": name} for name in children_names if name]\n",
        "\n",
        "                if children_list:\n",
        "                    family_info[\"children\"] = children_list\n",
        "\n",
        "        # Extract parents information\n",
        "        parents_patterns = [\n",
        "            r'(?:father|dad) is ([A-Za-z\\s]+)',\n",
        "            r'(?:mother|mom) is ([A-Za-z\\s]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in parents_patterns:\n",
        "            parent_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if parent_match:\n",
        "                parent_type = \"father\" if \"father\" in pattern or \"dad\" in pattern else \"mother\"\n",
        "                if \"parents\" not in family_info:\n",
        "                    family_info[\"parents\"] = {}\n",
        "                family_info[\"parents\"][parent_type] = parent_match.group(1).strip()\n",
        "\n",
        "        # Extract siblings information\n",
        "        siblings_patterns = [\n",
        "            r'(?:brother|sister)s? ([A-Za-z\\s,]+)',\n",
        "            r'has (\\d+) (?:brother|sister)s?'\n",
        "        ]\n",
        "\n",
        "        for pattern in siblings_patterns:\n",
        "            siblings_match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if siblings_match:\n",
        "                if siblings_match.group(1).isdigit():\n",
        "                    family_info[\"number_of_siblings\"] = int(siblings_match.group(1))\n",
        "                else:\n",
        "                    family_info[\"siblings\"] = [sib.strip() for sib in re.split(r',|and|&', siblings_match.group(1))]\n",
        "                break\n",
        "\n",
        "        return family_info\n",
        "\n",
        "    def _extract_education_info(self, text):\n",
        "        \"\"\"Extract comprehensive education information using NLP.\"\"\"\n",
        "        education_info = []\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        # Patterns for education information with more variations\n",
        "        education_patterns = [\n",
        "            r'([^.]+) from (.+?) in (\\d{4})',\n",
        "            r'educated at (.+?) in (\\d{4})',\n",
        "            r'graduated from (.+?)(?: in| with| year)? (\\d{4})',\n",
        "            r'completed (?:her|his|a) ([^.]+) (?:at|from) (.+?)(?: in| year)? (\\d{4})',\n",
        "            r'studied ([^.]+) at (.+?)(?: in| year)? (\\d{4})',\n",
        "            r'holds a ([^.]+) from (.+?)(?: |\\()(\\d{4})',\n",
        "            r'(?:bachelor|master|phd|doctorate|degree) (?:in|of) ([^.]+) from (.+?)(?: in| year)? (\\d{4})'\n",
        "        ]\n",
        "\n",
        "        # First pass: extract structured education info\n",
        "        for sentence in sentences:\n",
        "            for pattern in education_patterns:\n",
        "                match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                if match:\n",
        "                    education_entry = {}\n",
        "\n",
        "                    # Different patterns have different group arrangements\n",
        "                    if \"bachelor\" in pattern or \"master\" in pattern or \"phd\" in pattern:\n",
        "                        # Pattern for degree types\n",
        "                        field = match.group(1).strip()\n",
        "                        institution = match.group(2).strip()\n",
        "                        if len(match.groups()) > 2:\n",
        "                            year = match.group(3).strip()\n",
        "                            if year.isdigit():\n",
        "                                year = int(year)\n",
        "                        degree_type = pattern.split()[0].capitalize()  # Extract degree type from pattern\n",
        "                    elif len(match.groups()) == 3:\n",
        "                        # Standard pattern with degree, institution, year\n",
        "                        degree_type = match.group(1).strip()\n",
        "                        institution = match.group(2).strip()\n",
        "                        year = match.group(3).strip()\n",
        "                        if year.isdigit():\n",
        "                            year = int(year)\n",
        "                        field = \"\"\n",
        "                    else:\n",
        "                        # Pattern with just institution and year\n",
        "                        institution = match.group(1).strip()\n",
        "                        year = match.group(2).strip()\n",
        "                        if year.isdigit():\n",
        "                            year = int(year)\n",
        "                        degree_type = \"\"\n",
        "                        field = \"\"\n",
        "\n",
        "                    education_entry[\"institution\"] = institution\n",
        "                    if year:\n",
        "                        education_entry[\"year\"] = year\n",
        "\n",
        "                    # Add degree type and field if available\n",
        "                    if degree_type:\n",
        "                        education_entry[\"degree\"] = degree_type\n",
        "                    if field:\n",
        "                        education_entry[\"field\"] = field\n",
        "\n",
        "                    # Determine education level\n",
        "                    if any(term in (degree_type.lower() if degree_type else \"\") or term in sentence.lower() for term in\n",
        "                           [\"secondary\", \"high school\", \"diploma\"]):\n",
        "                        education_entry[\"level\"] = \"Secondary\"\n",
        "                    elif any(term in (degree_type.lower() if degree_type else \"\") or term in sentence.lower() for term in\n",
        "                             [\"university\", \"college\", \"tertiary\", \"bachelor\", \"master\", \"phd\", \"doctorate\"]):\n",
        "                        education_entry[\"level\"] = \"Tertiary\"\n",
        "                    else:\n",
        "                        # Use NLP to try to determine level\n",
        "                        doc = self.nlp(sentence)\n",
        "                        for entity in doc.ents:\n",
        "                            if entity.label_ == \"ORG\" and any(edu_term in entity.text.lower() for edu_term in\n",
        "                                                            [\"university\", \"college\", \"school\"]):\n",
        "                                if \"university\" in entity.text.lower() or \"college\" in entity.text.lower():\n",
        "                                    education_entry[\"level\"] = \"Tertiary\"\n",
        "                                else:\n",
        "                                    education_entry[\"level\"] = \"Secondary\"\n",
        "\n",
        "                    education_info.append(education_entry)\n",
        "\n",
        "        # Second pass: look for simple mentions of education that might be missed\n",
        "        if not education_info:\n",
        "            simple_edu_patterns = [\n",
        "                r'studied at ([^\\.]+)',\n",
        "                r'attended ([^\\.]+)',\n",
        "                r'education (?:at|from) ([^\\.]+)'\n",
        "            ]\n",
        "\n",
        "            for sentence in sentences:\n",
        "                for pattern in simple_edu_patterns:\n",
        "                    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                    if match:\n",
        "                        institution = match.group(1).strip()\n",
        "                        # Try to determine if it's a university/college or school\n",
        "                        if any(term in institution.lower() for term in [\"university\", \"college\"]):\n",
        "                            education_info.append({\n",
        "                                \"institution\": institution,\n",
        "                                \"level\": \"Tertiary\"\n",
        "                            })\n",
        "                        elif any(term in institution.lower() for term in [\"school\", \"academy\"]):\n",
        "                            education_info.append({\n",
        "                                \"institution\": institution,\n",
        "                                \"level\": \"Secondary\"\n",
        "                            })\n",
        "                        else:\n",
        "                            education_info.append({\n",
        "                                \"institution\": institution\n",
        "                            })\n",
        "\n",
        "        # Look for highest qualification mention\n",
        "        highest_qual_pattern = r'highest (?:qualification|education|degree) (?:is|:) ([^\\.]+)'\n",
        "        for sentence in sentences:\n",
        "            match = re.search(highest_qual_pattern, sentence, re.IGNORECASE)\n",
        "            if match:\n",
        "                # Add a special flag for highest qualification\n",
        "                qualification = match.group(1).strip()\n",
        "                # See if this qualification is already in our list\n",
        "                found = False\n",
        "                for entry in education_info:\n",
        "                    if \"degree\" in entry and qualification.lower() in entry[\"degree\"].lower():\n",
        "                        entry[\"highest\"] = True\n",
        "                        found = True\n",
        "                        break\n",
        "\n",
        "                # If not found, add as a separate entry\n",
        "                if not found:\n",
        "                    level = \"Tertiary\" if any(term in qualification.lower() for term in\n",
        "                                             [\"bachelor\", \"master\", \"phd\", \"doctorate\", \"university\", \"college\"]) else \"Secondary\"\n",
        "                    education_info.append({\n",
        "                        \"degree\": qualification,\n",
        "                        \"highest\": True,\n",
        "                        \"level\": level\n",
        "                    })\n",
        "\n",
        "        return education_info\n",
        "\n",
        "    def _extract_wealth_info(self, text):\n",
        "        \"\"\"Extract wealth information.\"\"\"\n",
        "        wealth_info = {}\n",
        "\n",
        "        # Extract savings\n",
        "        savings_pattern = r'saving (\\d+(?:,\\d+)*) ([A-Za-z]{3})'\n",
        "        savings_match = re.search(savings_pattern, text)\n",
        "        if savings_match:\n",
        "            amount_str = savings_match.group(1).replace(',', '')\n",
        "            wealth_info[\"savings\"] = {\n",
        "                \"amount\": int(amount_str),\n",
        "                \"currency\": savings_match.group(2)\n",
        "            }\n",
        "\n",
        "        # Extract property information\n",
        "        property_pattern = r'(?:does not have any properties|has (\\d+) properties)'\n",
        "        property_match = re.search(property_pattern, text, re.IGNORECASE)\n",
        "        if property_match:\n",
        "            wealth_info[\"has_properties\"] = not (\"does not\" in property_match.group(0).lower())\n",
        "            if wealth_info[\"has_properties\"] and property_match.group(1):\n",
        "                wealth_info[\"number_of_properties\"] = int(property_match.group(1))\n",
        "\n",
        "        # Extract inheritance\n",
        "        inheritance_pattern = r'(?:inheritance|inherited) of (\\d+(?:,\\d+)*) ([A-Za-z]{3}) in (\\d{4})'\n",
        "        inheritance_match = re.search(inheritance_pattern, text)\n",
        "        if inheritance_match:\n",
        "            amount_str = inheritance_match.group(1).replace(',', '')\n",
        "            wealth_info[\"inheritance\"] = {\n",
        "                \"amount\": int(amount_str),\n",
        "                \"currency\": inheritance_match.group(2),\n",
        "                \"year\": int(inheritance_match.group(3))\n",
        "            }\n",
        "\n",
        "            # Look for source of inheritance\n",
        "            context_start = max(0, text.find(inheritance_match.group(0)) - 100)\n",
        "            context_end = min(len(text), text.find(inheritance_match.group(0)) + 100)\n",
        "            context = text[context_start:context_end]\n",
        "\n",
        "            source_patterns = [\n",
        "                r'(?:grandfather|grandmother|father|mother|uncle|aunt|relative),\\s+a\\s+([^,\\.]+)',\n",
        "                r'from (?:his|her) ([^,]+), a ([^,\\.]+)'\n",
        "            ]\n",
        "\n",
        "            for pattern in source_patterns:\n",
        "                source_match = re.search(pattern, context)\n",
        "                if source_match:\n",
        "                    if len(source_match.groups()) == 1:\n",
        "                        relation = \"relative\"  # Default if not specified\n",
        "                        occupation = source_match.group(1).strip()\n",
        "                    else:\n",
        "                        relation = source_match.group(1).strip()\n",
        "                        occupation = source_match.group(2).strip()\n",
        "\n",
        "                    wealth_info[\"inheritance\"][\"source\"] = relation\n",
        "                    wealth_info[\"inheritance\"][\"source_occupation\"] = occupation\n",
        "                    break\n",
        "\n",
        "        # Extract investments and other assets using NLP\n",
        "        doc = self.nlp(text)\n",
        "        for sentence in sent_tokenize(text):\n",
        "            if \"investment\" in sentence.lower() or \"invest\" in sentence.lower():\n",
        "                investment_pattern = r'investments? (?:of|worth|valued at) (\\d+(?:,\\d+)*) ([A-Za-z]{3})'\n",
        "                investment_match = re.search(investment_pattern, sentence)\n",
        "                if investment_match:\n",
        "                    amount_str = investment_match.group(1).replace(',', '')\n",
        "                    wealth_info[\"investments\"] = {\n",
        "                        \"amount\": int(amount_str),\n",
        "                        \"currency\": investment_match.group(2)\n",
        "                    }\n",
        "\n",
        "        return wealth_info\n",
        "\n",
        "    def format_to_client_profile(self, client_info):\n",
        "        \"\"\"Format with more fields and handle empty values better.\"\"\"\n",
        "        formatted_json = {}\n",
        "\n",
        "        # Extract and format personal information with more fields\n",
        "        if \"personal_info\" in client_info:\n",
        "            personal = client_info[\"personal_info\"]\n",
        "            if \"name\" in personal:\n",
        "                # Split name into parts\n",
        "                name_parts = personal.get(\"name\", \"\").split()\n",
        "                if len(name_parts) >= 2:\n",
        "                    formatted_json[\"last_name\"] = name_parts[-1]\n",
        "                    formatted_json[\"first_middle_name\"] = \" \".join(name_parts[:-1])\n",
        "                else:\n",
        "                    formatted_json[\"last_name\"] = personal.get(\"name\", \"\")\n",
        "\n",
        "            # Map more fields\n",
        "            field_mappings = {\n",
        "                \"nationality\": \"nationality\",\n",
        "                \"gender\": \"gender\",\n",
        "                \"age\": \"age\",\n",
        "                \"date_of_birth\": \"date_of_birth\",\n",
        "                \"email\": \"email_address\",\n",
        "                \"phone\": \"phone_number\",\n",
        "                \"address\": \"residential_address\",\n",
        "                \"languages\": \"languages_spoken\"\n",
        "            }\n",
        "\n",
        "            for source, target in field_mappings.items():\n",
        "                if source in personal and personal[source]:\n",
        "                    formatted_json[target] = personal[source]\n",
        "\n",
        "        # More comprehensive mapping for other sections\n",
        "        # [additional mappings for family, education, occupation...]\n",
        "\n",
        "        # Include client preferences\n",
        "        if \"client_preferences\" in client_info and any(client_info[\"client_preferences\"]):\n",
        "            prefs = client_info[\"client_preferences\"]\n",
        "            if \"hobbies\" in prefs:\n",
        "                formatted_json[\"hobbies_interests\"] = prefs[\"hobbies\"]\n",
        "            if \"investment_preferences\" in prefs:\n",
        "                formatted_json[\"investment_preferences\"] = prefs[\"investment_preferences\"]\n",
        "            if \"communication_preference\" in prefs:\n",
        "                formatted_json[\"communication_preference\"] = prefs[\"communication_preference\"]\n",
        "\n",
        "        # Include risk profile\n",
        "        if \"risk_profile\" in client_info and any(client_info[\"risk_profile\"]):\n",
        "            risk = client_info[\"risk_profile\"]\n",
        "            if \"risk_tolerance\" in risk:\n",
        "                formatted_json[\"risk_profile\"] = risk[\"risk_tolerance\"]\n",
        "            if \"investment_horizon\" in risk:\n",
        "                formatted_json[\"investment_horizon\"] = risk[\"investment_horizon\"]\n",
        "            if \"financial_goals\" in risk:\n",
        "                formatted_json[\"financial_goals\"] = risk[\"financial_goals\"]\n",
        "\n",
        "        # Include relationship manager info\n",
        "        if \"relationship_manager\" in client_info and any(client_info[\"relationship_manager\"]):\n",
        "            rm = client_info[\"relationship_manager\"]\n",
        "            if \"name\" in rm:\n",
        "                formatted_json[\"relationship_manager\"] = rm[\"name\"]\n",
        "            if \"relation\" in rm:\n",
        "                formatted_json[\"rm_relation\"] = rm[\"relation\"]\n",
        "            if \"relationship_duration\" in rm:\n",
        "                formatted_json[\"client_since\"] = str(2025 - rm[\"relationship_duration\"])  # Assuming current year is 2025\n",
        "            if \"office_location\" in rm:\n",
        "                formatted_json[\"rm_office\"] = rm[\"office_location\"]\n",
        "\n",
        "        return formatted_json\n",
        "\n",
        "    def _extract_risk_profile(self, text):\n",
        "        \"\"\"Extract client risk profile information.\"\"\"\n",
        "        risk_profile = {}\n",
        "\n",
        "        # Extract risk tolerance\n",
        "        risk_tolerance_patterns = [\n",
        "            r'(?:risk tolerance|risk profile) (?:is|:) ([^\\.]+)',\n",
        "            r'has (?:a|an) ([a-zA-Z\\s]+) risk (?:tolerance|profile)',\n",
        "            r'comfortable with ([a-zA-Z\\s]+) risk',\n",
        "            r'(?:prefers|seeks) ([a-zA-Z\\s]+) risk'\n",
        "        ]\n",
        "\n",
        "        for pattern in risk_tolerance_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                risk_tolerance = match.group(1).strip()\n",
        "                risk_profile[\"risk_tolerance\"] = risk_tolerance\n",
        "                break\n",
        "\n",
        "        # Extract investment horizon\n",
        "        horizon_patterns = [\n",
        "            r'investment horizon (?:is|of) ([^\\.]+)',\n",
        "            r'invests for the ([^\\.]+) term',\n",
        "            r'(?:looking at|considering|preferring) ([a-zA-Z\\s]+) term investments',\n",
        "            r'time horizon (?:is|of) ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in horizon_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                investment_horizon = match.group(1).strip()\n",
        "                risk_profile[\"investment_horizon\"] = investment_horizon\n",
        "                break\n",
        "\n",
        "        # Extract financial goals\n",
        "        goal_patterns = [\n",
        "            r'financial goals? (?:include|is|are|:) ([^\\.]+)',\n",
        "            r'investing (?:for|to) ([^\\.]+)',\n",
        "            r'aims? to ([^\\.]+) through (?:his|her|their) investments',\n",
        "            r'goal is to ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in goal_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                goals_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                goals = [goal.strip() for goal in re.split(r',|and|&', goals_text)]\n",
        "                # Filter out empty strings\n",
        "                goals = [goal for goal in goals if goal]\n",
        "                risk_profile[\"financial_goals\"] = goals\n",
        "                break\n",
        "\n",
        "        # Extract preferred investment types\n",
        "        investment_type_patterns = [\n",
        "            r'prefers (?:to invest in|investments in) ([^\\.]+)',\n",
        "            r'investment preferences (?:include|:) ([^\\.]+)',\n",
        "            r'invests (?:primarily|mainly|mostly) in ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in investment_type_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                investment_types_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                investment_types = [type_.strip() for type_ in re.split(r',|and|&', investment_types_text)]\n",
        "                # Filter out empty strings\n",
        "                investment_types = [type_ for type_ in investment_types if type_]\n",
        "                risk_profile[\"preferred_investments\"] = investment_types\n",
        "                break\n",
        "\n",
        "        # Extract risk-related concerns\n",
        "        concern_patterns = [\n",
        "            r'concerned about ([^\\.]+) (?:in investments|when investing)',\n",
        "            r'worried about ([^\\.]+) (?:risks|aspects)',\n",
        "            r'cautious about ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in concern_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                risk_profile[\"risk_concerns\"] = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # Extract portfolio diversification preferences\n",
        "        diversification_patterns = [\n",
        "            r'(?:prefers|seeks|wants) (?:a|an) ([^\\.]+) diversified portfolio',\n",
        "            r'diversification (?:is|should be) ([^\\.]+)',\n",
        "            r'portfolio (?:should be|is) ([^\\.]+) diversified'\n",
        "        ]\n",
        "\n",
        "        for pattern in diversification_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                risk_profile[\"diversification_preference\"] = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        return risk_profile\n",
        "\n",
        "    def parse_text(self, text):\n",
        "        \"\"\"\n",
        "        Parse the client description text into a structured JSON format.\n",
        "        \"\"\"\n",
        "        # Extract sections from the text\n",
        "        sections = self._extract_sections(text)\n",
        "        print(f\"Found sections: {list(sections.keys())}\")\n",
        "\n",
        "        # Initialize the result structure\n",
        "        client_info = {\n",
        "            \"personal_info\": {},\n",
        "            \"family_info\": {},\n",
        "            \"education_info\": [],\n",
        "            \"occupation_info\": [],\n",
        "            \"wealth_info\": {},\n",
        "            \"client_preferences\": {},\n",
        "            \"risk_profile\": {},\n",
        "            \"relationship_manager\": {},\n",
        "            \"client_summary\": \"\"\n",
        "        }\n",
        "\n",
        "        # First pass: Process each identified section\n",
        "        for section_name, section_content in sections.items():\n",
        "            print(f\"Processing section: {section_name} ({len(section_content)} chars)\")\n",
        "            # Process by section type...\n",
        "\n",
        "        # Second pass: Process the entire text for any missed information\n",
        "        print(\"Processing entire text as fallback...\")\n",
        "        for field, extraction_method in [\n",
        "            (\"personal_info\", self._extract_personal_info),\n",
        "            (\"family_info\", self._extract_family_info),\n",
        "            (\"education_info\", self._extract_education_info),\n",
        "            (\"occupation_info\", self._extract_occupation_info),\n",
        "            (\"wealth_info\", self._extract_wealth_info),\n",
        "            (\"client_preferences\", self._extract_client_preferences),\n",
        "            (\"risk_profile\", self._extract_risk_profile),\n",
        "            (\"relationship_manager\", self._extract_rm_info)\n",
        "        ]:\n",
        "            # Only override if empty\n",
        "            if not client_info[field] or not any(client_info[field].values() if isinstance(client_info[field], dict) else client_info[field]):\n",
        "                result = extraction_method(text)\n",
        "                print(f\"Fallback extraction for {field}: Found {len(result) if isinstance(result, list) else len(result.keys()) if result else 0} items\")\n",
        "                client_info[field] = result\n",
        "\n",
        "        # Return raw client_info for debugging instead of formatted version\n",
        "        raw_data = client_info\n",
        "        formatted_data = self.format_to_client_profile(client_info)\n",
        "\n",
        "        print(f\"Raw data has {sum(len(v) if isinstance(v, list) else len(v.keys()) if isinstance(v, dict) else 0 for v in raw_data.values())} items\")\n",
        "        print(f\"Formatted data has {len(formatted_data.keys())} fields\")\n",
        "\n",
        "        return raw_data  # Return raw_data temporarily for debugging\n",
        "\n",
        "    def _extract_occupation_info(self, text):\n",
        "        \"\"\"Extract detailed occupation information from text.\"\"\"\n",
        "        occupation_info = []\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        # Patterns for current job\n",
        "        current_job_patterns = [\n",
        "            r'(?:currently|presently) (?:works|working) as (?:an?|the) ([^\\.]+) at ([^\\.]+)',\n",
        "            r'is (?:currently|presently) (?:an?|the) ([^\\.]+) at ([^\\.]+)',\n",
        "            r'(?:works|working|employed) as (?:an?|the) ([^\\.]+) (?:at|for|with) ([^\\.]+)',\n",
        "            r'position as (?:an?|the) ([^\\.]+) (?:at|in|with) ([^\\.]+)',\n",
        "            r'(?:is|as) (?:an?|the) ([^\\.]+) (?:at|in|with|for) ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        # Extract current job information\n",
        "        for sentence in sentences:\n",
        "            for pattern in current_job_patterns:\n",
        "                match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                if match:\n",
        "                    job_title = match.group(1).strip()\n",
        "                    # Clean up common issues with job title extraction\n",
        "                    job_title = re.sub(r'\\b(a|an|the)\\b', '', job_title).strip()\n",
        "\n",
        "                    company = match.group(2).strip()\n",
        "                    # Clean up company name (remove trailing punctuation)\n",
        "                    company = re.sub(r'[,\\.\\s]+$', '', company).strip()\n",
        "\n",
        "                    # Create job entry\n",
        "                    job_entry = {\n",
        "                        \"job_title\": job_title,\n",
        "                        \"company\": company,\n",
        "                        \"current\": True\n",
        "                    }\n",
        "\n",
        "                    # Try to extract start date if present\n",
        "                    date_pattern = r'since (\\d{4})'\n",
        "                    date_match = re.search(date_pattern, sentence)\n",
        "                    if date_match:\n",
        "                        job_entry[\"start_year\"] = int(date_match.group(1))\n",
        "\n",
        "                    # Try to extract industry/sector if present\n",
        "                    industry_pattern = r'in the ([a-zA-Z\\s]+) (?:industry|sector)'\n",
        "                    industry_match = re.search(industry_pattern, sentence)\n",
        "                    if industry_match:\n",
        "                        job_entry[\"industry\"] = industry_match.group(1).strip()\n",
        "\n",
        "                    occupation_info.append(job_entry)\n",
        "                    break\n",
        "\n",
        "        # Patterns for previous jobs\n",
        "        previous_job_patterns = [\n",
        "            r'(?:previously|formerly) (?:worked|working) as (?:an?|the) ([^\\.]+) at ([^\\.]+)',\n",
        "            r'(?:worked|was) as (?:an?|the) ([^\\.]+) (?:at|in|with) ([^\\.]+) (?:from|between) (\\d{4})(?:[^\\d]|$)',\n",
        "            r'(?:worked|was) (?:at|for|with) ([^\\.]+) as (?:an?|the) ([^\\.]+)',\n",
        "            r'experience as (?:an?|the) ([^\\.]+) at ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        # Extract previous job information\n",
        "        for sentence in sentences:\n",
        "            for pattern in previous_job_patterns:\n",
        "                match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                if match:\n",
        "                    # Handle different pattern groupings\n",
        "                    if \"from|between\" in pattern:\n",
        "                        job_title = match.group(1).strip()\n",
        "                        company = match.group(2).strip()\n",
        "                        start_year = int(match.group(3))\n",
        "\n",
        "                        # Try to extract end year if present\n",
        "                        end_year_pattern = r'(?:to|until|and) (\\d{4})'\n",
        "                        end_year_match = re.search(end_year_pattern, sentence)\n",
        "                        end_year = int(end_year_match.group(1)) if end_year_match else None\n",
        "                    elif \"experience as\" in pattern:\n",
        "                        job_title = match.group(1).strip()\n",
        "                        company = match.group(2).strip()\n",
        "                        start_year = None\n",
        "                        end_year = None\n",
        "                    elif \"worked|was at|for|with\" in pattern:\n",
        "                        company = match.group(1).strip()\n",
        "                        job_title = match.group(2).strip()\n",
        "                        start_year = None\n",
        "                        end_year = None\n",
        "                    else:\n",
        "                        job_title = match.group(1).strip()\n",
        "                        company = match.group(2).strip()\n",
        "                        start_year = None\n",
        "                        end_year = None\n",
        "\n",
        "                    # Clean up job title and company\n",
        "                    job_title = re.sub(r'\\b(a|an|the)\\b', '', job_title).strip()\n",
        "                    company = re.sub(r'[,\\.\\s]+$', '', company).strip()\n",
        "\n",
        "                    # Create job entry\n",
        "                    job_entry = {\n",
        "                        \"job_title\": job_title,\n",
        "                        \"company\": company,\n",
        "                        \"current\": False\n",
        "                    }\n",
        "\n",
        "                    # Add years if present\n",
        "                    if start_year:\n",
        "                        job_entry[\"start_year\"] = start_year\n",
        "                    if end_year:\n",
        "                        job_entry[\"end_year\"] = end_year\n",
        "\n",
        "                    # Try to extract industry/sector if present\n",
        "                    industry_pattern = r'in the ([a-zA-Z\\s]+) (?:industry|sector)'\n",
        "                    industry_match = re.search(industry_pattern, sentence)\n",
        "                    if industry_match:\n",
        "                        job_entry[\"industry\"] = industry_match.group(1).strip()\n",
        "\n",
        "                    # Check if it's not a duplicate of current job\n",
        "                    is_duplicate = False\n",
        "                    for existing_job in occupation_info:\n",
        "                        if (existing_job.get(\"job_title\", \"\").lower() == job_title.lower() and\n",
        "                            existing_job.get(\"company\", \"\").lower() == company.lower()):\n",
        "                            is_duplicate = True\n",
        "                            break\n",
        "\n",
        "                    if not is_duplicate:\n",
        "                        occupation_info.append(job_entry)\n",
        "                    break\n",
        "\n",
        "        # Extract career length if available\n",
        "        career_length_pattern = r'(?:career|experience) (?:of|spanning) (\\d+) years'\n",
        "        career_match = re.search(career_length_pattern, text, re.IGNORECASE)\n",
        "        if career_match:\n",
        "            # Add career length as a separate item in the info list\n",
        "            career_info = {\n",
        "                \"career_length_years\": int(career_match.group(1))\n",
        "            }\n",
        "            occupation_info.append(career_info)\n",
        "\n",
        "        # Extract industry expertise\n",
        "        expertise_patterns = [\n",
        "            r'expertise in ([^\\.]+)',\n",
        "            r'specialized in ([^\\.]+)',\n",
        "            r'specialization in ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in expertise_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                expertise = match.group(1).strip()\n",
        "                # Add expertise as a separate item\n",
        "                expertise_info = {\n",
        "                    \"expertise\": expertise\n",
        "                }\n",
        "                occupation_info.append(expertise_info)\n",
        "                break\n",
        "\n",
        "        # If no specific job entries were found, try simpler extraction\n",
        "        if not any((\"job_title\" in job) for job in occupation_info):\n",
        "            # Look for simple mentions of profession\n",
        "            profession_patterns = [\n",
        "                r'is an? ([A-Za-z\\s]+) (?:by profession|by trade)',\n",
        "                r'(?:profession|occupation) is ([^\\.]+)',\n",
        "                r'works as an? ([^\\.]+)',\n",
        "                r'career as an? ([^\\.]+)'\n",
        "            ]\n",
        "\n",
        "            for pattern in profession_patterns:\n",
        "                match = re.search(pattern, text, re.IGNORECASE)\n",
        "                if match:\n",
        "                    profession = match.group(1).strip()\n",
        "                    profession = re.sub(r'\\b(a|an|the)\\b', '', profession).strip()\n",
        "\n",
        "                    occupation_info.append({\n",
        "                        \"job_title\": profession,\n",
        "                        \"current\": True\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "            return occupation_info\n",
        "\n",
        "    def _extract_client_preferences(self, text):\n",
        "        \"\"\"Extract client preferences and interests.\"\"\"\n",
        "        preferences = {}\n",
        "\n",
        "        # Extract hobbies and interests\n",
        "        hobby_patterns = [\n",
        "            r'(?:hobbies|interests|enjoys|enjoys doing) (?:include|:)? ([^\\.]+)',\n",
        "            r'fond of ([^\\.]+)',\n",
        "            r'passionate about ([^\\.]+)',\n",
        "            r'leisure time (?:is spent|includes) ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in hobby_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                hobbies_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                hobbies = [hobby.strip() for hobby in re.split(r',|and|&', hobbies_text)]\n",
        "                # Filter out empty strings\n",
        "                hobbies = [hobby for hobby in hobbies if hobby]\n",
        "                preferences[\"hobbies\"] = hobbies\n",
        "                break\n",
        "\n",
        "        # Extract investment preferences\n",
        "        investment_patterns = [\n",
        "            r'prefers investments? in ([^\\.]+)',\n",
        "            r'investment preferences? (?:include|:) ([^\\.]+)',\n",
        "            r'interested in investing in ([^\\.]+)',\n",
        "            r'prefers (?:to invest|investing) in ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in investment_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                investment_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                investments = [inv.strip() for inv in re.split(r',|and|&', investment_text)]\n",
        "                # Filter out empty strings\n",
        "                investments = [inv for inv in investments if inv]\n",
        "                preferences[\"investment_preferences\"] = investments\n",
        "                break\n",
        "\n",
        "        # Extract communication preferences\n",
        "        communication_patterns = [\n",
        "            r'prefers (?:to be contacted|communication) (?:via|through|by) ([^\\.]+)',\n",
        "            r'communication preference is ([^\\.]+)',\n",
        "            r'(?:prefers|favors) ([^\\.]+) (?:as a means of|for) communication'\n",
        "        ]\n",
        "\n",
        "        for pattern in communication_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                preferences[\"communication_preference\"] = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # Extract meeting frequency preferences\n",
        "        meeting_patterns = [\n",
        "            r'prefers (?:to meet|meetings) ([^\\.]+)',\n",
        "            r'likes to be updated ([^\\.]+)',\n",
        "            r'prefers (?:to be contacted|contact) ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in meeting_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                meeting_pref = match.group(1).strip()\n",
        "                # Check if it contains frequency information\n",
        "                if re.search(r'(?:weekly|monthly|quarterly|annually|biweekly|daily)', meeting_pref, re.IGNORECASE):\n",
        "                    preferences[\"meeting_frequency\"] = meeting_pref\n",
        "                    break\n",
        "\n",
        "        # Extract financial service preferences\n",
        "        service_patterns = [\n",
        "            r'interested in ([^\\.]+) services',\n",
        "            r'looking for ([^\\.]+) (?:advice|services|solutions)',\n",
        "            r'seeking ([^\\.]+) (?:services|advice)'\n",
        "        ]\n",
        "\n",
        "        for pattern in service_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                service_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                services = [service.strip() for service in re.split(r',|and|&', service_text)]\n",
        "                # Filter out empty strings\n",
        "                services = [service for service in services if service]\n",
        "                preferences[\"service_preferences\"] = services\n",
        "                break\n",
        "\n",
        "        # Extract travel preferences\n",
        "        travel_patterns = [\n",
        "            r'(?:enjoys|likes) (?:traveling|travelling) to ([^\\.]+)',\n",
        "            r'(?:travel|travelling|traveling) (?:preferences|interests) (?:include|:) ([^\\.]+)',\n",
        "            r'traveled to ([^\\.]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in travel_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                travel_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                travel = [destination.strip() for destination in re.split(r',|and|&', travel_text)]\n",
        "                # Filter out empty strings\n",
        "                travel = [destination for destination in travel if destination]\n",
        "                preferences[\"travel_interests\"] = travel\n",
        "                break\n",
        "\n",
        "        # Extract lifestyle preferences\n",
        "        lifestyle_patterns = [\n",
        "            r'lifestyle (?:includes|revolves around) ([^\\.]+)',\n",
        "            r'values ([^\\.]+) in (?:life|day-to-day)',\n",
        "            r'prioritizes ([^\\.]+) in (?:life|personal matters)'\n",
        "        ]\n",
        "\n",
        "        for pattern in lifestyle_patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                lifestyle_text = match.group(1).strip()\n",
        "                # Split by commas, 'and', or '&'\n",
        "                lifestyle = [value.strip() for value in re.split(r',|and|&', lifestyle_text)]\n",
        "                # Filter out empty strings\n",
        "                lifestyle = [value for value in lifestyle if value]\n",
        "                preferences[\"lifestyle_values\"] = lifestyle\n",
        "                break\n",
        "\n",
        "        return preferences\n",
        "\n",
        "def process_client_description_file(file_path, output_json_path=None):\n",
        "    \"\"\"\n",
        "    Process a client description text file and convert it to JSON.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the client description text file\n",
        "        output_json_path (str, optional): Path where to save the JSON output.\n",
        "                                        If None, will use the same name as input but with .json extension\n",
        "\n",
        "    Returns:\n",
        "        dict: The structured JSON data\n",
        "    \"\"\"\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Input file not found: {file_path}\")\n",
        "\n",
        "    # Read the file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text_content = file.read()\n",
        "\n",
        "    # Process the content\n",
        "    parser = ClientDescriptionParser()\n",
        "    json_data = parser.parse_text(text_content)\n",
        "\n",
        "    # Determine output path if not provided\n",
        "    if output_json_path is None:\n",
        "        file_name, _ = os.path.splitext(file_path)\n",
        "        output_json_path = f\"{file_name}.json\"\n",
        "\n",
        "    # Write to JSON file\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
        "        json.dump(json_data, json_file, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Successfully processed {file_path}\")\n",
        "    print(f\"JSON file created at {output_json_path}\")\n",
        "\n",
        "    return json_data\n",
        "\n",
        "# Execute the processing if this script is run directly\n",
        "if __name__ == \"__main__\":\n",
        "    # Process the file at description_1.txt\n",
        "    file_path = \"description_2.txt\"\n",
        "    result = process_client_description_file(file_path)\n",
        "\n",
        "    # Print the result to console as well\n",
        "    print(\"\\nExtracted JSON data:\")\n",
        "    print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVTiFg7tVR9i",
        "outputId": "0face77a-f58b-4127-92db-8e24ae761f01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found sections: ['summary', 'family', 'education', 'occupation']\n",
            "Processing section: summary (145 chars)\n",
            "Processing section: family (72 chars)\n",
            "Processing section: education (131 chars)\n",
            "Processing section: occupation (668 chars)\n",
            "Processing entire text as fallback...\n",
            "Fallback extraction for personal_info: Found 5 items\n",
            "Fallback extraction for family_info: Found 0 items\n",
            "Fallback extraction for education_info: Found 1 items\n",
            "Fallback extraction for occupation_info: Found 0 items\n",
            "Fallback extraction for wealth_info: Found 0 items\n",
            "Fallback extraction for client_preferences: Found 0 items\n",
            "Fallback extraction for risk_profile: Found 0 items\n",
            "Fallback extraction for relationship_manager: Found 0 items\n",
            "Raw data has 6 items\n",
            "Formatted data has 5 fields\n",
            "Successfully processed description_2.txt\n",
            "JSON file created at description_2.json\n",
            "\n",
            "Extracted JSON data:\n",
            "{\n",
            "  \"personal_info\": {\n",
            "    \"name\": \"Lina Carolin Zimmermann\",\n",
            "    \"age\": 69,\n",
            "    \"nationality\": \"Germany\",\n",
            "    \"gender\": \"Female\",\n",
            "    \"profession\": \"seasoned professional\"\n",
            "  },\n",
            "  \"family_info\": {},\n",
            "  \"education_info\": [\n",
            "    {\n",
            "      \"institution\": \"University of Berlin\",\n",
            "      \"year\": 1978,\n",
            "      \"degree\": \"Lina earned her degree\",\n",
            "      \"level\": \"Tertiary\"\n",
            "    }\n",
            "  ],\n",
            "  \"occupation_info\": null,\n",
            "  \"wealth_info\": {},\n",
            "  \"client_preferences\": {},\n",
            "  \"risk_profile\": {},\n",
            "  \"relationship_manager\": {},\n",
            "  \"client_summary\": \"\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}